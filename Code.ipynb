{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training dataset and select the features (S1-S10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = read_csv(\"./data/stock_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1 = train[train.columns.tolist()[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute correlation between variable for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>S9</th>\n",
       "      <th>S10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.896286</td>\n",
       "      <td>0.915067</td>\n",
       "      <td>0.845219</td>\n",
       "      <td>0.934906</td>\n",
       "      <td>0.938336</td>\n",
       "      <td>0.920357</td>\n",
       "      <td>0.627016</td>\n",
       "      <td>0.919944</td>\n",
       "      <td>-0.635897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>-0.896286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.879798</td>\n",
       "      <td>-0.848230</td>\n",
       "      <td>-0.908228</td>\n",
       "      <td>-0.916752</td>\n",
       "      <td>-0.892510</td>\n",
       "      <td>-0.741348</td>\n",
       "      <td>-0.901114</td>\n",
       "      <td>0.680856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>0.915067</td>\n",
       "      <td>-0.879798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841010</td>\n",
       "      <td>0.945869</td>\n",
       "      <td>0.953039</td>\n",
       "      <td>0.918501</td>\n",
       "      <td>0.656271</td>\n",
       "      <td>0.933234</td>\n",
       "      <td>-0.663276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>0.845219</td>\n",
       "      <td>-0.848230</td>\n",
       "      <td>0.841010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896582</td>\n",
       "      <td>0.900291</td>\n",
       "      <td>0.880161</td>\n",
       "      <td>0.608569</td>\n",
       "      <td>0.910099</td>\n",
       "      <td>-0.606429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5</th>\n",
       "      <td>0.934906</td>\n",
       "      <td>-0.908228</td>\n",
       "      <td>0.945869</td>\n",
       "      <td>0.896582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>0.961122</td>\n",
       "      <td>0.688381</td>\n",
       "      <td>0.965143</td>\n",
       "      <td>-0.673424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S6</th>\n",
       "      <td>0.938336</td>\n",
       "      <td>-0.916752</td>\n",
       "      <td>0.953039</td>\n",
       "      <td>0.900291</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965351</td>\n",
       "      <td>0.702448</td>\n",
       "      <td>0.972927</td>\n",
       "      <td>-0.686498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7</th>\n",
       "      <td>0.920357</td>\n",
       "      <td>-0.892510</td>\n",
       "      <td>0.918501</td>\n",
       "      <td>0.880161</td>\n",
       "      <td>0.961122</td>\n",
       "      <td>0.965351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725190</td>\n",
       "      <td>0.938242</td>\n",
       "      <td>-0.641339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8</th>\n",
       "      <td>0.627016</td>\n",
       "      <td>-0.741348</td>\n",
       "      <td>0.656271</td>\n",
       "      <td>0.608569</td>\n",
       "      <td>0.688381</td>\n",
       "      <td>0.702448</td>\n",
       "      <td>0.725190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637574</td>\n",
       "      <td>-0.565303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S9</th>\n",
       "      <td>0.919944</td>\n",
       "      <td>-0.901114</td>\n",
       "      <td>0.933234</td>\n",
       "      <td>0.910099</td>\n",
       "      <td>0.965143</td>\n",
       "      <td>0.972927</td>\n",
       "      <td>0.938242</td>\n",
       "      <td>0.637574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.674329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S10</th>\n",
       "      <td>-0.635897</td>\n",
       "      <td>0.680856</td>\n",
       "      <td>-0.663276</td>\n",
       "      <td>-0.606429</td>\n",
       "      <td>-0.673424</td>\n",
       "      <td>-0.686498</td>\n",
       "      <td>-0.641339</td>\n",
       "      <td>-0.565303</td>\n",
       "      <td>-0.674329</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           S1        S2        S3        S4        S5        S6        S7  \\\n",
       "S1   1.000000 -0.896286  0.915067  0.845219  0.934906  0.938336  0.920357   \n",
       "S2  -0.896286  1.000000 -0.879798 -0.848230 -0.908228 -0.916752 -0.892510   \n",
       "S3   0.915067 -0.879798  1.000000  0.841010  0.945869  0.953039  0.918501   \n",
       "S4   0.845219 -0.848230  0.841010  1.000000  0.896582  0.900291  0.880161   \n",
       "S5   0.934906 -0.908228  0.945869  0.896582  1.000000  0.988365  0.961122   \n",
       "S6   0.938336 -0.916752  0.953039  0.900291  0.988365  1.000000  0.965351   \n",
       "S7   0.920357 -0.892510  0.918501  0.880161  0.961122  0.965351  1.000000   \n",
       "S8   0.627016 -0.741348  0.656271  0.608569  0.688381  0.702448  0.725190   \n",
       "S9   0.919944 -0.901114  0.933234  0.910099  0.965143  0.972927  0.938242   \n",
       "S10 -0.635897  0.680856 -0.663276 -0.606429 -0.673424 -0.686498 -0.641339   \n",
       "\n",
       "           S8        S9       S10  \n",
       "S1   0.627016  0.919944 -0.635897  \n",
       "S2  -0.741348 -0.901114  0.680856  \n",
       "S3   0.656271  0.933234 -0.663276  \n",
       "S4   0.608569  0.910099 -0.606429  \n",
       "S5   0.688381  0.965143 -0.673424  \n",
       "S6   0.702448  0.972927 -0.686498  \n",
       "S7   0.725190  0.938242 -0.641339  \n",
       "S8   1.000000  0.637574 -0.565303  \n",
       "S9   0.637574  1.000000 -0.674329  \n",
       "S10 -0.565303 -0.674329  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_corr(df):\n",
    "    corr = df.corr()\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAJKCAYAAAAImMC7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106159850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_corr(train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can try to manually evaluate the good features using the correlation matrix but this approach does not scale well. Also lets verfiy this matrix using machine learning models. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using 2 methods for feature selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Explicit Feature selection :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train x\n",
    "x = train[train1.columns.tolist()[1:]].get_values()[:40]\n",
    "#train y\n",
    "y = train[train1.columns.tolist()[:1]].get_values()[:40]\n",
    "\n",
    "y = y.reshape((y.shape[0],))\n",
    "\n",
    "#test y\n",
    "ydash = train[train1.columns.tolist()[:1]].get_values()[40:]\n",
    "\n",
    "ydash = ydash.reshape((ydash.shape[0],))\n",
    "#test x\n",
    "xdash = train[train1.columns.tolist()[1:]].get_values()[40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps RandomForestRegressor and RFE requires y in string or int, preparation of y values for these models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yprime = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yprime = np.asarray(yprime, dtype=\"|S6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18486171  0.10577999  0.02642044  0.19872537  0.09949958  0.28826443\n",
      "  0.00531066  0.04640495  0.04473287]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(x, y)\n",
    "# display the relative importance of stocks\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True  True False False False]\n",
      "[1 1 4 1 1 1 5 2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "# create the RFE model and select 5 attributes\n",
    "rfe = RFE(model, 5)\n",
    "rfe = rfe.fit(x, y)\n",
    "# top 5 stocks helping in prediction of S1\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### From the above 2 steps we confirm that the top 5 features which help in predicting S1 are S2, S3, S5, S6 and S7. Lets create a model based on these parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select features from train x and test x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selectx = x[:,rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectxdash = xdash[:,rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Used : For this regression/prediction task we would be using Epsilon-Support Vector Regression with an RBF Kernel. This model performs good with less data, in our case we have dataset of 50 data points for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Parameter selection we would be using GridSearchCV method, which allows us to find the best set of parameters for a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets define Parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Control Regularization No regularization, features already selected \n",
    "Cs = np.array([1000])\n",
    "# Controls Gamma for RBF\n",
    "gama = np.array([0.001, 0.002,0.005, 0.01, 0.05, 0.1, 0.5, 0.9,1])\n",
    "# Epsilon penalty\n",
    "eps = np.array([0.01, 0.05, 0.1, 0.5, 0.9,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=svr_rbf, param_grid=dict(C=Cs, gamma = gama, epsilon = eps ),n_jobs=-1, verbose = True,scoring =\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1000.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'epsilon': array([ 0.01,  0.05,  0.1 ,  0.5 ,  0.9 ,  1.  ]), 'C': array([1000]), 'gamma': array([ 0.001,  0.002,  0.005,  0.01 ,  0.05 ,  0.1  ,  0.5  ,  0.9  ,  1.   ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='mean_squared_error',\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(selectx,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best parameters and best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, 1000, 0.002)\n"
     ]
    }
   ],
   "source": [
    "print (clf.best_estimator_.epsilon, clf.best_estimator_.C, clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0914123132636\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Check the score on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himanshumisra/Desktop/DataScience/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "output = clf.score(selectxdash, ydash )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14938958331727686"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predict the values using selected parametes for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr_rbf_final = SVR(kernel='rbf', C=1000, gamma=0.002, epsilon = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = train[train1.columns.tolist()[1:]].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = train[train1.columns.tolist()[:1]].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = y1.reshape((y1.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model and predict the output for the output test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1000, cache_size=200, coef0=0.0, degree=3, epsilon=0.5, gamma=0.002,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_final.fit(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = read_csv(\"./data/stock_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testx = test[test.columns.tolist()[2:]].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_final = svr_rbf_final.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = DataFrame(output_final, columns=[\"S1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.223873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.046021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.613003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.120884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.032572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.206245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.733564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.457325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.035555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.511739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.468115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.653646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.486089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.382768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.204398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.748809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.887954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.676936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.981917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.013311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.055823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.568206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.035955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.134292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.420536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.017014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.357550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.458582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.250513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.099154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.505626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.485871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.926589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.024941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.175348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.724161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.314694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.801775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.122153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.191382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.067883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.131470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.123804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.371636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.490856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.197959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.350861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.482524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-1.213246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          S1\n",
       "0  -0.223873\n",
       "1   1.046021\n",
       "2  -0.613003\n",
       "3   0.157446\n",
       "4   2.120884\n",
       "5  -1.032572\n",
       "6   0.206245\n",
       "7   0.733564\n",
       "8  -0.457325\n",
       "9  -1.035555\n",
       "10  2.511739\n",
       "11 -0.468115\n",
       "12 -0.653646\n",
       "13  1.486089\n",
       "14  0.382768\n",
       "15 -1.204398\n",
       "16  0.748809\n",
       "17 -0.887954\n",
       "18 -0.676936\n",
       "19 -0.981917\n",
       "20  1.013311\n",
       "21 -1.055823\n",
       "22  1.568206\n",
       "23  0.035955\n",
       "24 -0.134292\n",
       "25 -0.420536\n",
       "26  0.017014\n",
       "27  1.357550\n",
       "28 -0.458582\n",
       "29  0.250513\n",
       "30  2.099154\n",
       "31 -0.505626\n",
       "32 -0.485871\n",
       "33  0.926589\n",
       "34  1.024941\n",
       "35  0.175348\n",
       "36 -0.724161\n",
       "37  0.314694\n",
       "38 -0.801775\n",
       "39  2.122153\n",
       "40 -1.191382\n",
       "41  1.067883\n",
       "42  0.131470\n",
       "43 -0.123804\n",
       "44 -0.371636\n",
       "45  1.490856\n",
       "46  0.197959\n",
       "47 -0.350861\n",
       "48 -0.482524\n",
       "49 -1.213246"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 : Implicit Feature slection using Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### This time we use regularization to select the features automatically, most of the steps are same except we would check several values of parameter C in SVR (less value of C means more regularization) and use the best to select the regularization parameter. We are also using all the variables (S2-S10) in prediction task, unlike previous method where we selected top 5 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There would be comment in the code as most of the steps are same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "Cs = np.array([0.01, 0.05, 0.1, 0.5, 0.9,1])\n",
    "\n",
    "gama = np.array([0.001, 0.002,0.005, 0.01, 0.05, 0.1, 0.5, 0.9,1])\n",
    "\n",
    "eps = np.array([0.01, 0.05, 0.1, 0.5, 0.9,1])\n",
    "\n",
    "Cs\n",
    "\n",
    "clf = GridSearchCV(estimator=svr_rbf, param_grid=dict(C=Cs, gamma = gama, epsilon = eps ),n_jobs=-1, verbose = True,scoring =\"mean_squared_error\")\n",
    "\n",
    "dict(C=Cs, d= Cs)\n",
    "\n",
    "x = train[train1.columns.tolist()[1:]].get_values()[:40]\n",
    "\n",
    "y = train[train1.columns.tolist()[:1]].get_values()[:40]\n",
    "\n",
    "y = y.reshape((y.shape[0],))\n",
    "\n",
    "ydash = train[train1.columns.tolist()[:1]].get_values()[40:]\n",
    "\n",
    "ydash = ydash.reshape((ydash.shape[0],))\n",
    "\n",
    "xdash = train[train1.columns.tolist()[1:]].get_values()[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1000.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'epsilon': array([ 0.01,  0.05,  0.1 ,  0.5 ,  0.9 ,  1.  ]), 'C': array([ 0.01,  0.05,  0.1 ,  0.5 ,  0.9 ,  1.  ]), 'gamma': array([ 0.001,  0.002,  0.005,  0.01 ,  0.05 ,  0.1  ,  0.5  ,  0.9  ,  1.   ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='mean_squared_error',\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.01, 1.0, 0.002)\n",
      "-0.148732577648\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_.epsilon,clf.best_estimator_.C,clf.best_estimator_.gamma)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = clf.score(xdash, ydash )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11518836074749816"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr_rbf_final = SVR(kernel='rbf', C=1, gamma=0.002, epsilon = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = train[train1.columns.tolist()[1:]].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = train[train1.columns.tolist()[:1]].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = y1.reshape((y1.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.01, gamma=0.002,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_final.fit(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = read_csv(\"./data/stock_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testx = test[test.columns.tolist()[2:]].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_final = svr_rbf_final.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = DataFrame({\"Date\":test[test.columns.tolist()[0]].get_values(), \"Value\":output_final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/11/14 0:00</td>\n",
       "      <td>-0.238854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/12/14 0:00</td>\n",
       "      <td>0.887702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/13/14 0:00</td>\n",
       "      <td>-0.710510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/14/14 0:00</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/15/14 0:00</td>\n",
       "      <td>1.853807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8/18/14 0:00</td>\n",
       "      <td>-1.126579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8/19/14 0:00</td>\n",
       "      <td>-0.081980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8/20/14 0:00</td>\n",
       "      <td>0.545631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8/21/14 0:00</td>\n",
       "      <td>-0.459528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8/22/14 0:00</td>\n",
       "      <td>-1.110085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8/25/14 0:00</td>\n",
       "      <td>2.317389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8/26/14 0:00</td>\n",
       "      <td>-0.337339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8/27/14 0:00</td>\n",
       "      <td>-0.673863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8/28/14 0:00</td>\n",
       "      <td>1.269638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8/29/14 0:00</td>\n",
       "      <td>0.258167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9/2/14 0:00</td>\n",
       "      <td>-1.470513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9/3/14 0:00</td>\n",
       "      <td>0.716582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9/4/14 0:00</td>\n",
       "      <td>-0.922823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9/5/14 0:00</td>\n",
       "      <td>-0.655462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9/8/14 0:00</td>\n",
       "      <td>-0.877924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9/9/14 0:00</td>\n",
       "      <td>1.090867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9/10/14 0:00</td>\n",
       "      <td>-1.172793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9/11/14 0:00</td>\n",
       "      <td>1.371817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9/12/14 0:00</td>\n",
       "      <td>-0.124611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9/15/14 0:00</td>\n",
       "      <td>-0.066085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9/16/14 0:00</td>\n",
       "      <td>-0.398676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9/17/14 0:00</td>\n",
       "      <td>0.025478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9/18/14 0:00</td>\n",
       "      <td>1.199144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9/19/14 0:00</td>\n",
       "      <td>-0.413777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9/22/14 0:00</td>\n",
       "      <td>0.302912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9/23/14 0:00</td>\n",
       "      <td>1.944562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9/24/14 0:00</td>\n",
       "      <td>-0.403820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9/25/14 0:00</td>\n",
       "      <td>-0.425776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9/26/14 0:00</td>\n",
       "      <td>0.836857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9/29/14 0:00</td>\n",
       "      <td>0.593718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9/30/14 0:00</td>\n",
       "      <td>0.095993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10/1/14 0:00</td>\n",
       "      <td>-0.598104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10/2/14 0:00</td>\n",
       "      <td>0.141820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10/3/14 0:00</td>\n",
       "      <td>-0.764227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10/6/14 0:00</td>\n",
       "      <td>2.073785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10/7/14 0:00</td>\n",
       "      <td>-1.407918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10/8/14 0:00</td>\n",
       "      <td>0.959162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10/9/14 0:00</td>\n",
       "      <td>0.033960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10/10/14 0:00</td>\n",
       "      <td>-0.251601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10/14/14 0:00</td>\n",
       "      <td>-0.261042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10/15/14 0:00</td>\n",
       "      <td>1.182187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10/16/14 0:00</td>\n",
       "      <td>-0.083323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10/17/14 0:00</td>\n",
       "      <td>-0.609965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10/20/14 0:00</td>\n",
       "      <td>-0.333417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10/21/14 0:00</td>\n",
       "      <td>-1.105330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date     Value\n",
       "0    8/11/14 0:00 -0.238854\n",
       "1    8/12/14 0:00  0.887702\n",
       "2    8/13/14 0:00 -0.710510\n",
       "3    8/14/14 0:00  0.000367\n",
       "4    8/15/14 0:00  1.853807\n",
       "5    8/18/14 0:00 -1.126579\n",
       "6    8/19/14 0:00 -0.081980\n",
       "7    8/20/14 0:00  0.545631\n",
       "8    8/21/14 0:00 -0.459528\n",
       "9    8/22/14 0:00 -1.110085\n",
       "10   8/25/14 0:00  2.317389\n",
       "11   8/26/14 0:00 -0.337339\n",
       "12   8/27/14 0:00 -0.673863\n",
       "13   8/28/14 0:00  1.269638\n",
       "14   8/29/14 0:00  0.258167\n",
       "15    9/2/14 0:00 -1.470513\n",
       "16    9/3/14 0:00  0.716582\n",
       "17    9/4/14 0:00 -0.922823\n",
       "18    9/5/14 0:00 -0.655462\n",
       "19    9/8/14 0:00 -0.877924\n",
       "20    9/9/14 0:00  1.090867\n",
       "21   9/10/14 0:00 -1.172793\n",
       "22   9/11/14 0:00  1.371817\n",
       "23   9/12/14 0:00 -0.124611\n",
       "24   9/15/14 0:00 -0.066085\n",
       "25   9/16/14 0:00 -0.398676\n",
       "26   9/17/14 0:00  0.025478\n",
       "27   9/18/14 0:00  1.199144\n",
       "28   9/19/14 0:00 -0.413777\n",
       "29   9/22/14 0:00  0.302912\n",
       "30   9/23/14 0:00  1.944562\n",
       "31   9/24/14 0:00 -0.403820\n",
       "32   9/25/14 0:00 -0.425776\n",
       "33   9/26/14 0:00  0.836857\n",
       "34   9/29/14 0:00  0.593718\n",
       "35   9/30/14 0:00  0.095993\n",
       "36   10/1/14 0:00 -0.598104\n",
       "37   10/2/14 0:00  0.141820\n",
       "38   10/3/14 0:00 -0.764227\n",
       "39   10/6/14 0:00  2.073785\n",
       "40   10/7/14 0:00 -1.407918\n",
       "41   10/8/14 0:00  0.959162\n",
       "42   10/9/14 0:00  0.033960\n",
       "43  10/10/14 0:00 -0.251601\n",
       "44  10/14/14 0:00 -0.261042\n",
       "45  10/15/14 0:00  1.182187\n",
       "46  10/16/14 0:00 -0.083323\n",
       "47  10/17/14 0:00 -0.609965\n",
       "48  10/20/14 0:00 -0.333417\n",
       "49  10/21/14 0:00 -1.105330"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Method selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####  Using the model generated using Regularization for final output as it is generalizing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
